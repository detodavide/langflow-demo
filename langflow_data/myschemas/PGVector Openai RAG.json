{"id":"1614d132-5c53-4a3c-8e10-8cc6261b953f","data":{"nodes":[{"data":{"id":"TextOutput-88QD6","node":{"template":{"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Record","Text"],"dynamic":false,"info":"Text or Record to be passed as output.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextOutput(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Text\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as output.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(self, input_value: Optional[Text] = \"\", record_template: Optional[str] = \"\") -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"{text}","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Display a text output in the Playground.","icon":"type","base_classes":["object","str","Text"],"display_name":"Extracted Chunks","documentation":"","custom_fields":{"input_value":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":true},"type":"TextOutput","description":"Display a text output in the Playground.","display_name":"Extracted Chunks","edited":false},"dragging":false,"height":297,"id":"TextOutput-88QD6","position":{"x":2332.7327888541295,"y":924.1083855711471},"positionAbsolute":{"x":2332.7327888541295,"y":924.1083855711471},"selected":false,"type":"genericNode","width":384},{"data":{"id":"OpenAIEmbeddings-GTnNH","node":{"base_classes":["Embeddings"],"beta":false,"custom_fields":{"allowed_special":null,"chunk_size":null,"client":null,"default_headers":null,"default_query":null,"deployment":null,"disallowed_special":null,"embedding_ctx_length":null,"max_retries":null,"model":null,"model_kwargs":null,"openai_api_base":null,"openai_api_key":null,"openai_api_type":null,"openai_api_version":null,"openai_organization":null,"openai_proxy":null,"request_timeout":null,"show_progress_bar":null,"skip_empty":null,"tiktoken_enable":null,"tiktoken_model_name":null},"description":"Generate embeddings using OpenAI models.","display_name":"OpenAI Embeddings","documentation":"","field_formatters":{},"field_order":[],"frozen":false,"output_types":["Embeddings"],"template":{"_type":"CustomComponent","allowed_special":{"advanced":true,"display_name":"Allowed Special","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"allowed_special","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":[]},"chunk_size":{"advanced":true,"display_name":"Chunk Size","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"chunk_size","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":1000},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Dict, List, Optional\n\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Embeddings, NestedDict\n\n\nclass OpenAIEmbeddingsComponent(CustomComponent):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n\n    def build_config(self):\n        return {\n            \"allowed_special\": {\n                \"display_name\": \"Allowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"default_headers\": {\n                \"display_name\": \"Default Headers\",\n                \"advanced\": True,\n                \"field_type\": \"dict\",\n            },\n            \"default_query\": {\n                \"display_name\": \"Default Query\",\n                \"advanced\": True,\n                \"field_type\": \"NestedDict\",\n            },\n            \"disallowed_special\": {\n                \"display_name\": \"Disallowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\"display_name\": \"Chunk Size\", \"advanced\": True},\n            \"client\": {\"display_name\": \"Client\", \"advanced\": True},\n            \"deployment\": {\"display_name\": \"Deployment\", \"advanced\": True},\n            \"embedding_ctx_length\": {\n                \"display_name\": \"Embedding Context Length\",\n                \"advanced\": True,\n            },\n            \"max_retries\": {\"display_name\": \"Max Retries\", \"advanced\": True},\n            \"model\": {\n                \"display_name\": \"Model\",\n                \"advanced\": False,\n                \"options\": [\n                    \"text-embedding-3-small\",\n                    \"text-embedding-3-large\",\n                    \"text-embedding-ada-002\",\n                ],\n            },\n            \"model_kwargs\": {\"display_name\": \"Model Kwargs\", \"advanced\": True},\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"password\": True,\n                \"advanced\": True,\n            },\n            \"openai_api_key\": {\"display_name\": \"OpenAI API Key\", \"password\": True},\n            \"openai_api_type\": {\n                \"display_name\": \"OpenAI API Type\",\n                \"advanced\": True,\n                \"password\": True,\n            },\n            \"openai_api_version\": {\n                \"display_name\": \"OpenAI API Version\",\n                \"advanced\": True,\n            },\n            \"openai_organization\": {\n                \"display_name\": \"OpenAI Organization\",\n                \"advanced\": True,\n            },\n            \"openai_proxy\": {\"display_name\": \"OpenAI Proxy\", \"advanced\": True},\n            \"request_timeout\": {\"display_name\": \"Request Timeout\", \"advanced\": True},\n            \"show_progress_bar\": {\n                \"display_name\": \"Show Progress Bar\",\n                \"advanced\": True,\n            },\n            \"skip_empty\": {\"display_name\": \"Skip Empty\", \"advanced\": True},\n            \"tiktoken_model_name\": {\n                \"display_name\": \"TikToken Model Name\",\n                \"advanced\": True,\n            },\n            \"tiktoken_enable\": {\"display_name\": \"TikToken Enable\", \"advanced\": True},\n            \"dimensions\": {\n                \"display_name\": \"Dimensions\",\n                \"info\": \"The number of dimensions the resulting output embeddings should have. Only supported by certain models.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        openai_api_key: str,\n        default_headers: Optional[Dict[str, str]] = None,\n        default_query: Optional[NestedDict] = {},\n        allowed_special: List[str] = [],\n        disallowed_special: List[str] = [\"all\"],\n        chunk_size: int = 1000,\n        deployment: str = \"text-embedding-ada-002\",\n        embedding_ctx_length: int = 8191,\n        max_retries: int = 6,\n        model: str = \"text-embedding-ada-002\",\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        openai_api_type: Optional[str] = None,\n        openai_api_version: Optional[str] = None,\n        openai_organization: Optional[str] = None,\n        openai_proxy: Optional[str] = None,\n        request_timeout: Optional[float] = None,\n        show_progress_bar: bool = False,\n        skip_empty: bool = False,\n        tiktoken_enable: bool = True,\n        tiktoken_model_name: Optional[str] = None,\n        dimensions: Optional[int] = None,\n    ) -> Embeddings:\n        # This is to avoid errors with Vector Stores (e.g Chroma)\n        if disallowed_special == [\"all\"]:\n            disallowed_special = \"all\"  # type: ignore\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        return OpenAIEmbeddings(\n            tiktoken_enabled=tiktoken_enable,\n            default_headers=default_headers,\n            default_query=default_query,\n            allowed_special=set(allowed_special),\n            disallowed_special=\"all\",\n            chunk_size=chunk_size,\n            deployment=deployment,\n            embedding_ctx_length=embedding_ctx_length,\n            max_retries=max_retries,\n            model=model,\n            model_kwargs=model_kwargs,\n            base_url=openai_api_base,\n            api_key=api_key,\n            openai_api_type=openai_api_type,\n            api_version=openai_api_version,\n            organization=openai_organization,\n            openai_proxy=openai_proxy,\n            timeout=request_timeout,\n            show_progress_bar=show_progress_bar,\n            skip_empty=skip_empty,\n            tiktoken_model_name=tiktoken_model_name,\n            dimensions=dimensions,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"default_headers":{"advanced":true,"display_name":"Default Headers","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"default_headers","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"dict"},"default_query":{"advanced":true,"display_name":"Default Query","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"default_query","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"NestedDict","value":{}},"deployment":{"advanced":true,"display_name":"Deployment","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"deployment","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"text-embedding-ada-002"},"disallowed_special":{"advanced":true,"display_name":"Disallowed Special","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"disallowed_special","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":["all"]},"embedding_ctx_length":{"advanced":true,"display_name":"Embedding Context Length","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"embedding_ctx_length","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":8191},"max_retries":{"advanced":true,"display_name":"Max Retries","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"max_retries","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":6},"model":{"advanced":false,"display_name":"Model","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":true,"load_from_db":false,"multiline":false,"name":"model","options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"],"password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"text-embedding-3-large"},"model_kwargs":{"advanced":true,"display_name":"Model Kwargs","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"model_kwargs","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"NestedDict","value":{}},"openai_api_base":{"advanced":true,"display_name":"OpenAI API Base","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_base","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"openai_api_key":{"advanced":false,"display_name":"OpenAI API Key","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"openai_api_type":{"advanced":true,"display_name":"OpenAI API Type","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_type","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"openai_api_version":{"advanced":true,"display_name":"OpenAI API Version","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_version","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"openai_organization":{"advanced":true,"display_name":"OpenAI Organization","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_organization","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"openai_proxy":{"advanced":true,"display_name":"OpenAI Proxy","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_proxy","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"request_timeout":{"advanced":true,"display_name":"Request Timeout","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"request_timeout","password":false,"placeholder":"","rangeSpec":{"max":1,"min":-1,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"type":"float"},"show_progress_bar":{"advanced":true,"display_name":"Show Progress Bar","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"show_progress_bar","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"bool","value":false},"skip_empty":{"advanced":true,"display_name":"Skip Empty","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"skip_empty","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"bool","value":false},"tiktoken_enable":{"advanced":true,"display_name":"TikToken Enable","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"tiktoken_enable","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"bool","value":true},"tiktoken_model_name":{"advanced":true,"display_name":"TikToken Model Name","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"tiktoken_model_name","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"}}},"type":"OpenAIEmbeddings"},"dragging":false,"height":391,"id":"OpenAIEmbeddings-GTnNH","position":{"x":1109.3650666725605,"y":964.2616875605394},"selected":false,"type":"genericNode","width":384,"positionAbsolute":{"x":1109.3650666725605,"y":964.2616875605394}},{"data":{"id":"OpenAIModel-92y9h","node":{"base_classes":["object","Text","str"],"beta":false,"custom_fields":{"input_value":null,"max_tokens":null,"model_kwargs":null,"model_name":null,"openai_api_base":null,"openai_api_key":null,"stream":null,"system_message":null,"temperature":null},"description":"Generates text using OpenAI LLMs.","display_name":"OpenAI","documentation":"","field_formatters":{},"field_order":["max_tokens","model_kwargs","model_name","openai_api_base","openai_api_key","temperature","input_value","system_message","stream"],"frozen":false,"icon":"OpenAI","output_types":["Text"],"template":{"_type":"CustomComponent","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import NestedDict, Text\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n\n    field_order = [\n        \"max_tokens\",\n        \"model_kwargs\",\n        \"model_name\",\n        \"openai_api_base\",\n        \"openai_api_key\",\n        \"temperature\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self):\n        return {\n            \"input_value\": {\"display_name\": \"Input\", \"input_types\": [\"Text\", \"Record\", \"Prompt\"]},\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"advanced\": True,\n                \"info\": \"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"advanced\": True,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"advanced\": False,\n                \"options\": MODEL_NAMES,\n            },\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"advanced\": True,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"info\": \"The OpenAI API Key to use for the OpenAI model.\",\n                \"advanced\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"advanced\": False,\n                \"value\": 0.1,\n            },\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        openai_api_key: str,\n        temperature: float = 0.1,\n        model_name: str = \"gpt-3.5-turbo\",\n        max_tokens: Optional[int] = 256,\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature,\n        )\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"advanced":false,"display_name":"Input","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text","Record","Prompt"],"list":false,"load_from_db":false,"multiline":false,"name":"input_value","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str"},"max_tokens":{"advanced":true,"display_name":"Max Tokens","dynamic":false,"fileTypes":[],"file_path":"","info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","list":false,"load_from_db":false,"multiline":false,"name":"max_tokens","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":256},"model_kwargs":{"advanced":true,"display_name":"Model Kwargs","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"model_kwargs","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"NestedDict","value":{}},"model_name":{"advanced":false,"display_name":"Model Name","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":true,"load_from_db":false,"multiline":false,"name":"model_name","options":["gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"gpt-4o"},"openai_api_base":{"advanced":true,"display_name":"OpenAI API Base","dynamic":false,"fileTypes":[],"file_path":"","info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_base","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"openai_api_key":{"advanced":false,"display_name":"OpenAI API Key","dynamic":false,"fileTypes":[],"file_path":"","info":"The OpenAI API Key to use for the OpenAI model.","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"stream":{"advanced":true,"display_name":"Stream","dynamic":false,"fileTypes":[],"file_path":"","info":"Stream the response from the model. Streaming works only in Chat.","list":false,"load_from_db":false,"multiline":false,"name":"stream","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"bool","value":false},"system_message":{"advanced":true,"display_name":"System Message","dynamic":false,"fileTypes":[],"file_path":"","info":"System message to pass to the model.","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"system_message","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"temperature":{"advanced":false,"display_name":"Temperature","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"temperature","password":false,"placeholder":"","rangeSpec":{"max":1,"min":-1,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"type":"float","value":"0.0"}}},"type":"OpenAIModel"},"dragging":false,"height":571,"id":"OpenAIModel-92y9h","position":{"x":3410.117202077183,"y":431.2038048137648},"positionAbsolute":{"x":3410.117202077183,"y":431.2038048137648},"selected":false,"type":"genericNode","width":384},{"data":{"description":"Create a prompt template with dynamic variables.","display_name":"Prompt","id":"Prompt-eB2HE","node":{"template":{"_type":"CustomComponent","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import CustomComponent\nfrom langflow.field_typing import TemplateField\nfrom langflow.field_typing.prompt import Prompt\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    async def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Prompt:\n        prompt = await Prompt.from_template_and_variables(template, kwargs)\n        self.status = prompt.format_text()\n        return prompt\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"context":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"context","display_name":"context","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"question":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"question","display_name":"question","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"template":{"advanced":false,"display_name":"Template","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"template","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"prompt","value":"Use the following pieces of information to answer the user's question.\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\n\nContext: {context}\n\nQuestion: {question}\n\nOnly return the helpful answer below and nothing else.\nHelpful answer:"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["object","str","Text"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["context","question"]},"output_types":["Prompt"],"full_path":null,"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"error":null},"type":"Prompt"},"dragging":false,"height":513,"id":"Prompt-eB2HE","position":{"x":2862.6389778635,"y":425.27450493715605},"positionAbsolute":{"x":2862.6389778635,"y":425.27450493715605},"selected":false,"type":"genericNode","width":384},{"data":{"id":"ChatOutput-FYaJt","node":{"base_classes":["object","Text","Record","str"],"beta":false,"custom_fields":{"input_value":null,"record_template":null,"return_record":null,"sender":null,"sender_name":null,"session_id":null},"description":"Display a chat message in the Playground.","display_name":"Chat Output","documentation":"","field_formatters":{},"field_order":[],"frozen":false,"icon":"ChatOutput","output_types":["Message","Text"],"template":{"_type":"CustomComponent","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        return_message: Optional[bool] = False,\n    ) -> Union[Message, Text]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            files=files,\n            return_message=return_message,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"advanced":false,"display_name":"Text","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":true,"name":"input_value","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"sender":{"advanced":true,"display_name":"Sender Type","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":true,"load_from_db":false,"multiline":false,"name":"sender","options":["Machine","User"],"password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"Machine"},"sender_name":{"advanced":false,"display_name":"Sender Name","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"sender_name","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"AI"},"session_id":{"advanced":true,"display_name":"Session ID","dynamic":false,"fileTypes":[],"file_path":"","info":"If provided, the message will be stored in the memory.","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"session_id","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"}}},"type":"ChatOutput"},"dragging":false,"height":391,"id":"ChatOutput-FYaJt","position":{"x":3890.5847387698986,"y":591.8574945882358},"positionAbsolute":{"x":3890.5847387698986,"y":591.8574945882358},"selected":false,"type":"genericNode","width":384},{"data":{"id":"File-zN2Ty","node":{"base_classes":["Record"],"beta":false,"custom_fields":{"path":null,"silent_errors":null},"description":"A generic file loader.","display_name":"File","documentation":"","field_formatters":{},"field_order":[],"frozen":false,"icon":"file-text","output_types":["Record"],"template":{"_type":"CustomComponent","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from pathlib import Path\nfrom typing import Any, Dict\n\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_record\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\n\n\nclass FileComponent(CustomComponent):\n    display_name = \"File\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n\n    def build_config(self) -> Dict[str, Any]:\n        return {\n            \"path\": {\n                \"display_name\": \"Path\",\n                \"field_type\": \"file\",\n                \"file_types\": TEXT_FILE_TYPES,\n                \"info\": f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n            },\n            \"silent_errors\": {\n                \"display_name\": \"Silent Errors\",\n                \"advanced\": True,\n                \"info\": \"If true, errors will not raise an exception.\",\n            },\n        }\n\n    def load_file(self, path: str, silent_errors: bool = False) -> Record:\n        resolved_path = self.resolve_path(path)\n        path_obj = Path(resolved_path)\n        extension = path_obj.suffix[1:].lower()\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n        record = parse_text_file_to_record(resolved_path, silent_errors)\n        self.status = record if record else \"No data\"\n        return record or Record()\n\n    def build(\n        self,\n        path: str,\n        silent_errors: bool = False,\n    ) -> Record:\n        record = self.load_file(path, silent_errors)\n        self.status = record\n        return record\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"path":{"advanced":false,"display_name":"Path","dynamic":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx"],"file_path":"1614d132-5c53-4a3c-8e10-8cc6261b953f/uber_10q_march_2022.md","info":"Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx","list":false,"load_from_db":false,"multiline":false,"name":"path","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"file","value":""},"silent_errors":{"advanced":true,"display_name":"Silent Errors","dynamic":false,"fileTypes":[],"file_path":"","info":"If true, errors will not raise an exception.","list":false,"load_from_db":false,"multiline":false,"name":"silent_errors","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"bool","value":false}}},"type":"File"},"dragging":false,"height":289,"id":"File-zN2Ty","position":{"x":2257.233450682836,"y":1747.5389618367233},"positionAbsolute":{"x":2257.233450682836,"y":1747.5389618367233},"selected":false,"type":"genericNode","width":384},{"data":{"id":"RecursiveCharacterTextSplitter-ENQtr","node":{"base_classes":["Record"],"beta":false,"custom_fields":{"chunk_overlap":null,"chunk_size":null,"inputs":null,"separators":null},"description":"Split text into chunks of a specified length.","display_name":"Recursive Character Text Splitter","documentation":"https://docs.langflow.org/components/text-splitters#recursivecharactertextsplitter","field_formatters":{},"field_order":[],"frozen":false,"output_types":["Record"],"template":{"_type":"CustomComponent","chunk_overlap":{"advanced":false,"display_name":"Chunk Overlap","dynamic":false,"fileTypes":[],"file_path":"","info":"The amount of overlap between chunks.","list":false,"load_from_db":false,"multiline":false,"name":"chunk_overlap","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":"100"},"chunk_size":{"advanced":false,"display_name":"Chunk Size","dynamic":false,"fileTypes":[],"file_path":"","info":"The maximum length of each chunk.","list":false,"load_from_db":false,"multiline":false,"name":"chunk_size","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":"2000"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_core.documents import Document\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\nfrom langflow.utils.util import build_loader_repr_from_records, unescape_string\n\n\nclass RecursiveCharacterTextSplitterComponent(CustomComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text into chunks of a specified length.\"\n    documentation: str = \"https://docs.langflow.org/components/text-splitters#recursivecharactertextsplitter\"\n\n    def build_config(self):\n        return {\n            \"inputs\": {\n                \"display_name\": \"Input\",\n                \"info\": \"The texts to split.\",\n                \"input_types\": [\"Document\", \"Record\"],\n            },\n            \"separators\": {\n                \"display_name\": \"Separators\",\n                \"info\": 'The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\n                \"display_name\": \"Chunk Size\",\n                \"info\": \"The maximum length of each chunk.\",\n                \"field_type\": \"int\",\n                \"value\": 1000,\n            },\n            \"chunk_overlap\": {\n                \"display_name\": \"Chunk Overlap\",\n                \"info\": \"The amount of overlap between chunks.\",\n                \"field_type\": \"int\",\n                \"value\": 200,\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        inputs: list[Document],\n        separators: Optional[list[str]] = None,\n        chunk_size: Optional[int] = 1000,\n        chunk_overlap: Optional[int] = 200,\n    ) -> list[Record]:\n        \"\"\"\n        Split text into chunks of a specified length.\n\n        Args:\n            separators (list[str]): The characters to split on.\n            chunk_size (int): The maximum length of each chunk.\n            chunk_overlap (int): The amount of overlap between chunks.\n            length_function (function): The function to use to calculate the length of the text.\n\n        Returns:\n            list[str]: The chunks of text.\n        \"\"\"\n\n        if separators == \"\":\n            separators = None\n        elif separators:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [unescape_string(x) for x in separators]\n\n        # Make sure chunk_size and chunk_overlap are ints\n        if isinstance(chunk_size, str):\n            chunk_size = int(chunk_size)\n        if isinstance(chunk_overlap, str):\n            chunk_overlap = int(chunk_overlap)\n        splitter = RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=chunk_size,\n            chunk_overlap=chunk_overlap,\n        )\n        documents = []\n        for _input in inputs:\n            if isinstance(_input, Record):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        docs = splitter.split_documents(documents)\n        records = self.to_records(docs)\n        self.repr_value = build_loader_repr_from_records(records)\n        return records\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"inputs":{"advanced":false,"display_name":"Input","dynamic":false,"fileTypes":[],"file_path":"","info":"The texts to split.","input_types":["Document","Record"],"list":true,"load_from_db":false,"multiline":false,"name":"inputs","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"Document"},"separators":{"advanced":false,"display_name":"Separators","dynamic":false,"fileTypes":[],"file_path":"","info":"The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].","input_types":["Text"],"list":true,"load_from_db":false,"multiline":false,"name":"separators","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":[""]}}},"type":"RecursiveCharacterTextSplitter"},"dragging":false,"height":509,"id":"RecursiveCharacterTextSplitter-ENQtr","position":{"x":2791.013514133929,"y":1462.9588953494142},"positionAbsolute":{"x":2791.013514133929,"y":1462.9588953494142},"selected":false,"type":"genericNode","width":384},{"data":{"id":"OpenAIEmbeddings-7ADlB","node":{"base_classes":["Embeddings"],"beta":false,"custom_fields":{"allowed_special":null,"chunk_size":null,"client":null,"default_headers":null,"default_query":null,"deployment":null,"disallowed_special":null,"embedding_ctx_length":null,"max_retries":null,"model":null,"model_kwargs":null,"openai_api_base":null,"openai_api_key":null,"openai_api_type":null,"openai_api_version":null,"openai_organization":null,"openai_proxy":null,"request_timeout":null,"show_progress_bar":null,"skip_empty":null,"tiktoken_enable":null,"tiktoken_model_name":null},"description":"Generate embeddings using OpenAI models.","display_name":"OpenAI Embeddings","documentation":"","field_formatters":{},"field_order":[],"frozen":false,"output_types":["Embeddings"],"template":{"_type":"CustomComponent","allowed_special":{"advanced":true,"display_name":"Allowed Special","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"allowed_special","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":[]},"chunk_size":{"advanced":true,"display_name":"Chunk Size","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"chunk_size","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":1000},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Dict, List, Optional\n\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Embeddings, NestedDict\n\n\nclass OpenAIEmbeddingsComponent(CustomComponent):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n\n    def build_config(self):\n        return {\n            \"allowed_special\": {\n                \"display_name\": \"Allowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"default_headers\": {\n                \"display_name\": \"Default Headers\",\n                \"advanced\": True,\n                \"field_type\": \"dict\",\n            },\n            \"default_query\": {\n                \"display_name\": \"Default Query\",\n                \"advanced\": True,\n                \"field_type\": \"NestedDict\",\n            },\n            \"disallowed_special\": {\n                \"display_name\": \"Disallowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\"display_name\": \"Chunk Size\", \"advanced\": True},\n            \"client\": {\"display_name\": \"Client\", \"advanced\": True},\n            \"deployment\": {\"display_name\": \"Deployment\", \"advanced\": True},\n            \"embedding_ctx_length\": {\n                \"display_name\": \"Embedding Context Length\",\n                \"advanced\": True,\n            },\n            \"max_retries\": {\"display_name\": \"Max Retries\", \"advanced\": True},\n            \"model\": {\n                \"display_name\": \"Model\",\n                \"advanced\": False,\n                \"options\": [\n                    \"text-embedding-3-small\",\n                    \"text-embedding-3-large\",\n                    \"text-embedding-ada-002\",\n                ],\n            },\n            \"model_kwargs\": {\"display_name\": \"Model Kwargs\", \"advanced\": True},\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"password\": True,\n                \"advanced\": True,\n            },\n            \"openai_api_key\": {\"display_name\": \"OpenAI API Key\", \"password\": True},\n            \"openai_api_type\": {\n                \"display_name\": \"OpenAI API Type\",\n                \"advanced\": True,\n                \"password\": True,\n            },\n            \"openai_api_version\": {\n                \"display_name\": \"OpenAI API Version\",\n                \"advanced\": True,\n            },\n            \"openai_organization\": {\n                \"display_name\": \"OpenAI Organization\",\n                \"advanced\": True,\n            },\n            \"openai_proxy\": {\"display_name\": \"OpenAI Proxy\", \"advanced\": True},\n            \"request_timeout\": {\"display_name\": \"Request Timeout\", \"advanced\": True},\n            \"show_progress_bar\": {\n                \"display_name\": \"Show Progress Bar\",\n                \"advanced\": True,\n            },\n            \"skip_empty\": {\"display_name\": \"Skip Empty\", \"advanced\": True},\n            \"tiktoken_model_name\": {\n                \"display_name\": \"TikToken Model Name\",\n                \"advanced\": True,\n            },\n            \"tiktoken_enable\": {\"display_name\": \"TikToken Enable\", \"advanced\": True},\n            \"dimensions\": {\n                \"display_name\": \"Dimensions\",\n                \"info\": \"The number of dimensions the resulting output embeddings should have. Only supported by certain models.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        openai_api_key: str,\n        default_headers: Optional[Dict[str, str]] = None,\n        default_query: Optional[NestedDict] = {},\n        allowed_special: List[str] = [],\n        disallowed_special: List[str] = [\"all\"],\n        chunk_size: int = 1000,\n        deployment: str = \"text-embedding-ada-002\",\n        embedding_ctx_length: int = 8191,\n        max_retries: int = 6,\n        model: str = \"text-embedding-ada-002\",\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        openai_api_type: Optional[str] = None,\n        openai_api_version: Optional[str] = None,\n        openai_organization: Optional[str] = None,\n        openai_proxy: Optional[str] = None,\n        request_timeout: Optional[float] = None,\n        show_progress_bar: bool = False,\n        skip_empty: bool = False,\n        tiktoken_enable: bool = True,\n        tiktoken_model_name: Optional[str] = None,\n        dimensions: Optional[int] = None,\n    ) -> Embeddings:\n        # This is to avoid errors with Vector Stores (e.g Chroma)\n        if disallowed_special == [\"all\"]:\n            disallowed_special = \"all\"  # type: ignore\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        return OpenAIEmbeddings(\n            tiktoken_enabled=tiktoken_enable,\n            default_headers=default_headers,\n            default_query=default_query,\n            allowed_special=set(allowed_special),\n            disallowed_special=\"all\",\n            chunk_size=chunk_size,\n            deployment=deployment,\n            embedding_ctx_length=embedding_ctx_length,\n            max_retries=max_retries,\n            model=model,\n            model_kwargs=model_kwargs,\n            base_url=openai_api_base,\n            api_key=api_key,\n            openai_api_type=openai_api_type,\n            api_version=openai_api_version,\n            organization=openai_organization,\n            openai_proxy=openai_proxy,\n            timeout=request_timeout,\n            show_progress_bar=show_progress_bar,\n            skip_empty=skip_empty,\n            tiktoken_model_name=tiktoken_model_name,\n            dimensions=dimensions,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"default_headers":{"advanced":true,"display_name":"Default Headers","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"default_headers","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"dict"},"default_query":{"advanced":true,"display_name":"Default Query","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"default_query","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"NestedDict","value":{}},"deployment":{"advanced":true,"display_name":"Deployment","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"deployment","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"text-embedding-ada-002"},"disallowed_special":{"advanced":true,"display_name":"Disallowed Special","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"disallowed_special","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":["all"]},"embedding_ctx_length":{"advanced":true,"display_name":"Embedding Context Length","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"embedding_ctx_length","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":8191},"max_retries":{"advanced":true,"display_name":"Max Retries","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"max_retries","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":6},"model":{"advanced":false,"display_name":"Model","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":true,"load_from_db":false,"multiline":false,"name":"model","options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"],"password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"text-embedding-3-large"},"model_kwargs":{"advanced":true,"display_name":"Model Kwargs","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"model_kwargs","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"NestedDict","value":{}},"openai_api_base":{"advanced":true,"display_name":"OpenAI API Base","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_base","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"openai_api_key":{"advanced":false,"display_name":"OpenAI API Key","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"openai_api_type":{"advanced":true,"display_name":"OpenAI API Type","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_type","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"openai_api_version":{"advanced":true,"display_name":"OpenAI API Version","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_version","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"openai_organization":{"advanced":true,"display_name":"OpenAI Organization","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_organization","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"openai_proxy":{"advanced":true,"display_name":"OpenAI Proxy","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_proxy","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"request_timeout":{"advanced":true,"display_name":"Request Timeout","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"request_timeout","password":false,"placeholder":"","rangeSpec":{"max":1,"min":-1,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"type":"float"},"show_progress_bar":{"advanced":true,"display_name":"Show Progress Bar","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"show_progress_bar","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"bool","value":false},"skip_empty":{"advanced":true,"display_name":"Skip Empty","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"skip_empty","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"bool","value":false},"tiktoken_enable":{"advanced":true,"display_name":"TikToken Enable","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"tiktoken_enable","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"bool","value":true},"tiktoken_model_name":{"advanced":true,"display_name":"TikToken Model Name","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"tiktoken_model_name","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"}}},"type":"OpenAIEmbeddings"},"dragging":false,"height":391,"id":"OpenAIEmbeddings-7ADlB","position":{"x":2785.3325570479287,"y":2114.6633012385655},"positionAbsolute":{"x":2785.3325570479287,"y":2114.6633012385655},"selected":false,"type":"genericNode","width":384},{"id":"pgvector-QykYT","type":"genericNode","position":{"x":3396.8474382170193,"y":1660.7644394301326},"data":{"type":"pgvector","node":{"template":{"embedding":{"type":"Embeddings","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"embedding","display_name":"Embedding","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"inputs":{"type":"Record","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"inputs","display_name":"Input","advanced":false,"input_types":["Document","Record"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langchain_community.vectorstores.pgvector import PGVector\nfrom langchain_core.embeddings import Embeddings\nfrom langchain_core.retrievers import BaseRetriever\nfrom langchain_core.vectorstores import VectorStore\n\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\n\n\nclass PGVectorComponent(CustomComponent):\n    \"\"\"\n    A custom component for implementing a Vector Store using PostgreSQL.\n    \"\"\"\n\n    display_name: str = \"PGVector\"\n    description: str = \"Implementation of Vector Store using PostgreSQL\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/pgvector\"\n\n    def build_config(self):\n        \"\"\"\n        Builds the configuration for the component.\n\n        Returns:\n        - dict: A dictionary containing the configuration options for the component.\n        \"\"\"\n        return {\n            \"code\": {\"show\": False},\n            \"inputs\": {\"display_name\": \"Input\", \"input_types\": [\"Document\", \"Record\"]},\n            \"embedding\": {\"display_name\": \"Embedding\"},\n            \"pg_server_url\": {\n                \"display_name\": \"PostgreSQL Server Connection String\",\n                \"advanced\": False,\n            },\n            \"collection_name\": {\"display_name\": \"Table\", \"advanced\": False},\n        }\n\n    def build(\n        self,\n        embedding: Embeddings,\n        pg_server_url: str,\n        collection_name: str,\n        inputs: Optional[Record] = None,\n    ) -> Union[VectorStore, BaseRetriever]:\n        \"\"\"\n        Builds the Vector Store or BaseRetriever object.\n\n        Args:\n        - embedding (Embeddings): The embeddings to use for the Vector Store.\n        - documents (Optional[Document]): The documents to use for the Vector Store.\n        - collection_name (str): The name of the PG table.\n        - pg_server_url (str): The URL for the PG server.\n\n        Returns:\n        - VectorStore: The Vector Store object.\n        \"\"\"\n\n        documents = []\n        for _input in inputs or []:\n            if isinstance(_input, Record):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        try:\n            if documents is None:\n                vector_store = PGVector.from_existing_index(\n                    embedding=embedding,\n                    collection_name=collection_name,\n                    connection_string=pg_server_url,\n                )\n            else:\n                vector_store = PGVector.from_documents(\n                    embedding=embedding,\n                    documents=documents,  # type: ignore\n                    collection_name=collection_name,\n                    connection_string=pg_server_url,\n                )\n        except Exception as e:\n            raise RuntimeError(f\"Failed to build PGVector: {e}\")\n        return vector_store\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"Table","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"uber_10k"},"pg_server_url":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"pg_server_url","display_name":"PostgreSQL Server Connection String","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"postgresql+psycopg2://myuser:mypassword@vector_db:5432/mydatabase2"},"_type":"CustomComponent"},"description":"Implementation of Vector Store using PostgreSQL","base_classes":["BaseRetriever","Generic","object","Runnable","RunnableSerializable","Serializable","VectorStore"],"display_name":"PGVector","documentation":"https://python.langchain.com/docs/integrations/vectorstores/pgvector","custom_fields":{"embedding":null,"pg_server_url":null,"collection_name":null,"inputs":null},"output_types":["VectorStore","BaseRetriever"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"pgvector-QykYT"},"selected":false,"width":384,"height":515,"positionAbsolute":{"x":3396.8474382170193,"y":1660.7644394301326},"dragging":false},{"id":"pgvectorSearch-9zvbD","type":"genericNode","position":{"x":1770.5646802357915,"y":861.9196751050084},"data":{"type":"pgvectorSearch","node":{"template":{"embedding":{"type":"Embeddings","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"embedding","display_name":"Embedding","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"Message","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List\n\nfrom langchain_core.embeddings import Embeddings\n\nfrom langflow.components.vectorstores.base.model import LCVectorStoreComponent\nfrom langflow.components.vectorstores.pgvector import PGVectorComponent\nfrom langflow.schema.message import Message\nfrom langflow.field_typing import Text\nfrom langflow.schema import Record\n\n\nclass PGVectorSearchComponent(PGVectorComponent, LCVectorStoreComponent):\n    display_name: str = \"PGVector Search\"\n    description: str = \"Search a PGVector Store for similar documents.\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/pgvector\"\n\n    def build_config(self):\n        \"\"\"\n        Builds the configuration for the component.\n\n        Returns:\n        - dict: A dictionary containing the configuration options for the component.\n        \"\"\"\n        return {\n            \"code\": {\"show\": False},\n            \"embedding\": {\"display_name\": \"Embedding\"},\n            \"search_type\": {\n                \"display_name\": \"Search Type\",\n                \"options\": [\"Similarity\", \"MMR\"],\n            },\n            \"pg_server_url\": {\n                \"display_name\": \"PostgreSQL Server Connection String\",\n                \"advanced\": False,\n            },\n            \"collection_name\": {\"display_name\": \"Table\", \"advanced\": False},\n            \"input_value\": {\"display_name\": \"Input\"},\n            \"number_of_results\": {\n                \"display_name\": \"Number of Results\",\n                \"info\": \"Number of results to return.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(  # type: ignore[override]\n        self,\n        input_value: Message,\n        embedding: Embeddings,\n        search_type: str,\n        pg_server_url: str,\n        collection_name: str,\n        number_of_results: int = 4,\n    ) -> List[Record]:\n        \"\"\"\n        Builds the Vector Store or BaseRetriever object.\n\n        Args:\n        - input_value (str): The input value to search for.\n        - embedding (Embeddings): The embeddings to use for the Vector Store.\n        - collection_name (str): The name of the PG table.\n        - pg_server_url (str): The URL for the PG server.\n\n        Returns:\n        - VectorStore: The Vector Store object.\n        \"\"\"\n        try:\n            vector_store = super().build(\n                embedding=embedding,\n                pg_server_url=pg_server_url,\n                collection_name=collection_name,\n            )\n        except Exception as e:\n            raise RuntimeError(f\"Failed to build PGVector: {e}\")\n        return self.search_with_vector_store(\n            input_value=input_value.text, search_type=search_type, vector_store=vector_store, k=number_of_results\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"Table","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"uber_10k"},"number_of_results":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":4,"fileTypes":[],"file_path":"","password":false,"name":"number_of_results","display_name":"Number of Results","advanced":true,"dynamic":false,"info":"Number of results to return.","load_from_db":false,"title_case":false},"pg_server_url":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"pg_server_url","display_name":"PostgreSQL Server Connection String","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"postgresql+psycopg2://myuser:mypassword@vector_db:5432/mydatabase2"},"search_type":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"options":["Similarity","MMR"],"name":"search_type","display_name":"Search Type","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"Similarity"},"_type":"CustomComponent"},"description":"Search a PGVector Store for similar documents.","base_classes":["Record"],"display_name":"PGVector Search","documentation":"https://python.langchain.com/docs/integrations/vectorstores/pgvector","custom_fields":{"input_value":null,"embedding":null,"search_type":null,"pg_server_url":null,"collection_name":null,"number_of_results":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":true},"id":"pgvectorSearch-9zvbD","description":"Search a PGVector Store for similar documents.","display_name":"PGVector Search"},"selected":false,"width":384,"height":581,"positionAbsolute":{"x":1770.5646802357915,"y":861.9196751050084},"dragging":false},{"id":"ChatInput-u1wBD","type":"genericNode","position":{"x":1226.122153625653,"y":350.45729304835464},"data":{"type":"ChatInput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.schema.message import Message\nfrom langflow.field_typing import Text\nfrom typing import Union\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    def build_config(self):\n        build_config = super().build_config()\n        build_config[\"input_value\"] = {\n            \"input_types\": [],\n            \"display_name\": \"Text\",\n            \"multiline\": True,\n        }\n        build_config[\"return_message\"] = {\n            \"display_name\": \"Return Record\",\n            \"advanced\": True,\n        }\n\n        return build_config\n\n    def build(\n        self,\n        sender: Optional[str] = \"User\",\n        sender_name: Optional[str] = \"User\",\n        input_value: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        session_id: Optional[str] = None,\n        return_message: Optional[bool] = True,\n    ) -> Union[Message, Text]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            files=files,\n            session_id=session_id,\n            return_message=return_message,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":[],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"value":"What is the Total cash and cash equivalents, and restricted cash and cash equivalents for reconciliation ?"},"return_message":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":true,"fileTypes":[],"file_path":"","password":false,"name":"return_message","display_name":"Return Record","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["Message","object","str","Text"],"display_name":"Chat Input","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"files":null,"session_id":null,"return_message":null},"output_types":["Message","Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatInput-u1wBD"},"selected":false,"width":384,"height":297,"positionAbsolute":{"x":1226.122153625653,"y":350.45729304835464},"dragging":false}],"edges":[{"className":"","data":{"sourceHandle":{"baseClasses":["object","Text","str"],"dataType":"OpenAIModel","id":"OpenAIModel-92y9h"},"targetHandle":{"fieldName":"input_value","id":"ChatOutput-FYaJt","inputTypes":["Text"],"type":"str"}},"id":"reactflow__edge-OpenAIModel-92y9h{baseClasses:[object,Text,str],dataType:OpenAIModel,id:OpenAIModel-92y9h}-ChatOutput-FYaJt{fieldName:input_value,id:ChatOutput-FYaJt,inputTypes:[Text],type:str}","selected":false,"source":"OpenAIModel-92y9h","sourceHandle":"{baseClasses:[object,Text,str],dataType:OpenAIModel,id:OpenAIModel-92y9h}","style":{"stroke":"#555"},"target":"ChatOutput-FYaJt","targetHandle":"{fieldName:input_value,id:ChatOutput-FYaJt,inputTypes:[Text],type:str}"},{"className":"","data":{"sourceHandle":{"baseClasses":["Record"],"dataType":"File","id":"File-zN2Ty"},"targetHandle":{"fieldName":"inputs","id":"RecursiveCharacterTextSplitter-ENQtr","inputTypes":["Document","Record"],"type":"Document"}},"id":"reactflow__edge-File-zN2Ty{baseClasses:[Record],dataType:File,id:File-zN2Ty}-RecursiveCharacterTextSplitter-ENQtr{fieldName:inputs,id:RecursiveCharacterTextSplitter-ENQtr,inputTypes:[Document,Record],type:Document}","selected":false,"source":"File-zN2Ty","sourceHandle":"{baseClasses:[Record],dataType:File,id:File-zN2Ty}","style":{"stroke":"#555"},"target":"RecursiveCharacterTextSplitter-ENQtr","targetHandle":"{fieldName:inputs,id:RecursiveCharacterTextSplitter-ENQtr,inputTypes:[Document,Record],type:Document}"},{"source":"OpenAIEmbeddings-7ADlB","sourceHandle":"{baseClasses:[Embeddings],dataType:OpenAIEmbeddings,id:OpenAIEmbeddings-7ADlB}","target":"pgvector-QykYT","targetHandle":"{fieldName:embedding,id:pgvector-QykYT,inputTypes:null,type:Embeddings}","data":{"targetHandle":{"fieldName":"embedding","id":"pgvector-QykYT","inputTypes":null,"type":"Embeddings"},"sourceHandle":{"baseClasses":["Embeddings"],"dataType":"OpenAIEmbeddings","id":"OpenAIEmbeddings-7ADlB"}},"id":"reactflow__edge-OpenAIEmbeddings-7ADlB{baseClasses:[Embeddings],dataType:OpenAIEmbeddings,id:OpenAIEmbeddings-7ADlB}-pgvector-QykYT{fieldName:embedding,id:pgvector-QykYT,inputTypes:null,type:Embeddings}","className":""},{"source":"RecursiveCharacterTextSplitter-ENQtr","sourceHandle":"{baseClasses:[Record],dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-ENQtr}","target":"pgvector-QykYT","targetHandle":"{fieldName:inputs,id:pgvector-QykYT,inputTypes:[Document,Record],type:Record}","data":{"targetHandle":{"fieldName":"inputs","id":"pgvector-QykYT","inputTypes":["Document","Record"],"type":"Record"},"sourceHandle":{"baseClasses":["Record"],"dataType":"RecursiveCharacterTextSplitter","id":"RecursiveCharacterTextSplitter-ENQtr"}},"id":"reactflow__edge-RecursiveCharacterTextSplitter-ENQtr{baseClasses:[Record],dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-ENQtr}-pgvector-QykYT{fieldName:inputs,id:pgvector-QykYT,inputTypes:[Document,Record],type:Record}","className":""},{"source":"OpenAIEmbeddings-GTnNH","sourceHandle":"{baseClasses:[Embeddings],dataType:OpenAIEmbeddings,id:OpenAIEmbeddings-GTnNH}","target":"pgvectorSearch-9zvbD","targetHandle":"{fieldName:embedding,id:pgvectorSearch-9zvbD,inputTypes:null,type:Embeddings}","data":{"targetHandle":{"fieldName":"embedding","id":"pgvectorSearch-9zvbD","inputTypes":null,"type":"Embeddings"},"sourceHandle":{"baseClasses":["Embeddings"],"dataType":"OpenAIEmbeddings","id":"OpenAIEmbeddings-GTnNH"}},"id":"reactflow__edge-OpenAIEmbeddings-GTnNH{baseClasses:[Embeddings],dataType:OpenAIEmbeddings,id:OpenAIEmbeddings-GTnNH}-pgvectorSearch-9zvbD{fieldName:embedding,id:pgvectorSearch-9zvbD,inputTypes:null,type:Embeddings}","className":""},{"source":"pgvectorSearch-9zvbD","sourceHandle":"{baseClasses:[Record],dataType:pgvectorSearch,id:pgvectorSearch-9zvbD}","target":"TextOutput-88QD6","targetHandle":"{fieldName:input_value,id:TextOutput-88QD6,inputTypes:[Record,Text],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"TextOutput-88QD6","inputTypes":["Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Record"],"dataType":"pgvectorSearch","id":"pgvectorSearch-9zvbD"}},"id":"reactflow__edge-pgvectorSearch-9zvbD{baseClasses:[Record],dataType:pgvectorSearch,id:pgvectorSearch-9zvbD}-TextOutput-88QD6{fieldName:input_value,id:TextOutput-88QD6,inputTypes:[Record,Text],type:str}","className":""},{"source":"TextOutput-88QD6","sourceHandle":"{baseClasses:[object,str,Text],dataType:TextOutput,id:TextOutput-88QD6}","target":"Prompt-eB2HE","targetHandle":"{fieldName:context,id:Prompt-eB2HE,inputTypes:[Document,Message,Record,Text],type:str}","data":{"targetHandle":{"fieldName":"context","id":"Prompt-eB2HE","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"TextOutput","id":"TextOutput-88QD6"}},"id":"reactflow__edge-TextOutput-88QD6{baseClasses:[object,str,Text],dataType:TextOutput,id:TextOutput-88QD6}-Prompt-eB2HE{fieldName:context,id:Prompt-eB2HE,inputTypes:[Document,Message,Record,Text],type:str}","className":""},{"source":"Prompt-eB2HE","sourceHandle":"{baseClasses:[object,str,Text],dataType:Prompt,id:Prompt-eB2HE}","target":"OpenAIModel-92y9h","targetHandle":"{fieldName:input_value,id:OpenAIModel-92y9h,inputTypes:[Text,Record,Prompt],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-92y9h","inputTypes":["Text","Record","Prompt"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"Prompt","id":"Prompt-eB2HE"}},"id":"reactflow__edge-Prompt-eB2HE{baseClasses:[object,str,Text],dataType:Prompt,id:Prompt-eB2HE}-OpenAIModel-92y9h{fieldName:input_value,id:OpenAIModel-92y9h,inputTypes:[Text,Record,Prompt],type:str}","className":""},{"source":"ChatInput-u1wBD","sourceHandle":"{baseClasses:[Message,object,str,Text],dataType:ChatInput,id:ChatInput-u1wBD}","target":"Prompt-eB2HE","targetHandle":"{fieldName:question,id:Prompt-eB2HE,inputTypes:[Document,Message,Record,Text],type:str}","data":{"targetHandle":{"fieldName":"question","id":"Prompt-eB2HE","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Message","object","str","Text"],"dataType":"ChatInput","id":"ChatInput-u1wBD"}},"id":"reactflow__edge-ChatInput-u1wBD{baseClasses:[Message,object,str,Text],dataType:ChatInput,id:ChatInput-u1wBD}-Prompt-eB2HE{fieldName:question,id:Prompt-eB2HE,inputTypes:[Document,Message,Record,Text],type:str}"},{"source":"ChatInput-u1wBD","sourceHandle":"{baseClasses:[Message,object,str,Text],dataType:ChatInput,id:ChatInput-u1wBD}","target":"pgvectorSearch-9zvbD","targetHandle":"{fieldName:input_value,id:pgvectorSearch-9zvbD,inputTypes:null,type:Message}","data":{"targetHandle":{"fieldName":"input_value","id":"pgvectorSearch-9zvbD","inputTypes":null,"type":"Message"},"sourceHandle":{"baseClasses":["Message","object","str","Text"],"dataType":"ChatInput","id":"ChatInput-u1wBD"}},"id":"reactflow__edge-ChatInput-u1wBD{baseClasses:[Message,object,str,Text],dataType:ChatInput,id:ChatInput-u1wBD}-pgvectorSearch-9zvbD{fieldName:input_value,id:pgvectorSearch-9zvbD,inputTypes:null,type:Message}"}],"viewport":{"x":-240.35526302755432,"y":-0.6354584791074558,"zoom":0.43169937307443024}},"description":"pgvector openai rag","name":"PGVector Openai RAG","last_tested_version":"1.0.0a61","is_component":false}