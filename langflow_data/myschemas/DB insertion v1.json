{"id":"66aa374e-5166-4c64-8c0b-82a95b9481ae","data":{"nodes":[{"id":"ChatOutput-pThdQ","type":"genericNode","position":{"x":1815.8752298812537,"y":1905.2160352204548},"data":{"type":"ChatOutput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        return_message: Optional[bool] = False,\n    ) -> Union[Message, Text]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            files=files,\n            return_message=return_message,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"return_message":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_message","display_name":"Return Message","advanced":true,"dynamic":false,"info":"Return the message as a Message containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"AI","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message","object","str","Text"],"display_name":"Chat Output","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"files":null,"return_message":null},"output_types":["Message","Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatOutput-pThdQ"},"selected":false,"width":384,"height":297,"dragging":false,"positionAbsolute":{"x":1815.8752298812537,"y":1905.2160352204548}},{"id":"ChatInput-j3Aim","type":"genericNode","position":{"x":412.0224294588551,"y":2437.7559776813805},"data":{"type":"ChatInput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.schema.message import Message\nfrom langflow.field_typing import Text\nfrom typing import Union\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    def build_config(self):\n        build_config = super().build_config()\n        build_config[\"input_value\"] = {\n            \"input_types\": [],\n            \"display_name\": \"Text\",\n            \"multiline\": True,\n        }\n        build_config[\"return_message\"] = {\n            \"display_name\": \"Return Record\",\n            \"advanced\": True,\n        }\n\n        return build_config\n\n    def build(\n        self,\n        sender: Optional[str] = \"User\",\n        sender_name: Optional[str] = \"User\",\n        input_value: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        session_id: Optional[str] = None,\n        return_message: Optional[bool] = True,\n    ) -> Union[Message, Text]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            files=files,\n            session_id=session_id,\n            return_message=return_message,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":[],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"value":"I want to book an appointment"},"return_message":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":true,"fileTypes":[],"file_path":"","password":false,"name":"return_message","display_name":"Return Record","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["Message","object","str","Text"],"display_name":"Chat Input","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"files":null,"session_id":null,"return_message":null},"output_types":["Message","Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatInput-j3Aim"},"selected":false,"width":384,"height":297,"dragging":false,"positionAbsolute":{"x":412.0224294588551,"y":2437.7559776813805}},{"id":"SQLAgent-ar5dR","type":"genericNode","position":{"x":1016.2150820466156,"y":2831.0852802814247},"data":{"type":"SQLAgent","node":{"template":{"llm":{"type":"BaseLanguageModel","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"llm","display_name":"LLM","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Callable, Union\n\nfrom langchain.agents import AgentExecutor\nfrom langchain_community.agent_toolkits import SQLDatabaseToolkit\nfrom langchain_community.agent_toolkits.sql.base import create_sql_agent\nfrom langchain_community.utilities import SQLDatabase\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import BaseLanguageModel\n\n\nclass SQLAgentComponent(CustomComponent):\n    display_name = \"SQLAgent\"\n    description = \"Construct an SQL agent from an LLM and tools.\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"database_uri\": {\"display_name\": \"Database URI\"},\n            \"verbose\": {\"display_name\": \"Verbose\", \"value\": False, \"advanced\": True},\n        }\n\n    def build(\n        self,\n        llm: BaseLanguageModel,\n        database_uri: str,\n        verbose: bool = False,\n    ) -> Union[AgentExecutor, Callable]:\n        db = SQLDatabase.from_uri(database_uri)\n        toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n        return create_sql_agent(llm=llm, toolkit=toolkit)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"database_uri":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"database_uri","display_name":"Database URI","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"postgresql+psycopg2://myuser:mypassword@testdb:5432/testdb1"},"verbose":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"verbose","display_name":"Verbose","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Construct an SQL agent from an LLM and tools.","base_classes":["AgentExecutor","Callable","Chain","Generic","object","Runnable","RunnableSerializable","Serializable"],"display_name":"SQLAgent","documentation":"","custom_fields":{"llm":null,"database_uri":null,"verbose":null},"output_types":["AgentExecutor","Callable"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"SQLAgent-ar5dR"},"selected":false,"width":384,"height":345,"positionAbsolute":{"x":1016.2150820466156,"y":2831.0852802814247},"dragging":false},{"id":"GroqModelSpecs-MTknA","type":"genericNode","position":{"x":509.27024226800756,"y":2848.279119946775},"data":{"type":"GroqModelSpecs","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_groq import ChatGroq\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.groq_constants import MODEL_NAMES\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import BaseLanguageModel\n\n\nclass GroqModelSpecs(LCModelComponent):\n    display_name: str = \"Groq\"\n    description: str = \"Generate text using Groq.\"\n    icon = \"Groq\"\n\n    field_order = [\n        \"groq_api_key\",\n        \"model\",\n        \"max_output_tokens\",\n        \"temperature\",\n        \"top_k\",\n        \"top_p\",\n        \"n\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self):\n        return {\n            \"groq_api_key\": {\n                \"display_name\": \"Groq API Key\",\n                \"info\": \"API key for the Groq API.\",\n                \"password\": True,\n            },\n            \"groq_api_base\": {\n                \"display_name\": \"Groq API Base\",\n                \"info\": \"Base URL path for API requests, leave blank if not using a proxy or service emulator.\",\n                \"advanced\": True,\n            },\n            \"max_tokens\": {\n                \"display_name\": \"Max Output Tokens\",\n                \"info\": \"The maximum number of tokens to generate.\",\n                \"advanced\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"info\": \"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\",\n            },\n            \"n\": {\n                \"display_name\": \"N\",\n                \"info\": \"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n                \"advanced\": True,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model\",\n                \"info\": \"The name of the model to use. Supported examples: gemini-pro\",\n                \"options\": MODEL_NAMES,\n            },\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        groq_api_key: str,\n        model_name: str,\n        groq_api_base: Optional[str] = None,\n        max_tokens: Optional[int] = None,\n        temperature: float = 0.1,\n        n: Optional[int] = 1,\n        stream: bool = False,\n    ) -> BaseLanguageModel:\n        return ChatGroq(\n            model_name=model_name,\n            max_tokens=max_tokens or None,  # type: ignore\n            temperature=temperature,\n            groq_api_base=groq_api_base,\n            n=n or 1,\n            groq_api_key=SecretStr(groq_api_key),\n            streaming=stream,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"groq_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"groq_api_base","display_name":"Groq API Base","advanced":true,"dynamic":false,"info":"Base URL path for API requests, leave blank if not using a proxy or service emulator.","load_from_db":false,"title_case":false,"input_types":["Text"]},"groq_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"groq_api_key","display_name":"Groq API Key","advanced":false,"dynamic":false,"info":"API key for the Groq API.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Output Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate.","load_from_db":false,"title_case":false},"model_name":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"options":["llama3-8b-8192","llama3-70b-8192","mixtral-8x7b-32768","gemma-7b-it"],"name":"model_name","display_name":"Model","advanced":false,"dynamic":false,"info":"The name of the model to use. Supported examples: gemini-pro","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"llama3-70b-8192"},"n":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":1,"fileTypes":[],"file_path":"","password":false,"name":"n","display_name":"N","advanced":true,"dynamic":false,"info":"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.","load_from_db":false,"title_case":false},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":0.1,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generate text using Groq.","icon":"Groq","base_classes":["BaseLanguageModel","Generic","object","Runnable","RunnableSerializable","Serializable"],"display_name":"Groq","documentation":"","custom_fields":{"groq_api_key":null,"model_name":null,"groq_api_base":null,"max_tokens":null,"temperature":null,"n":null,"stream":null},"output_types":["BaseLanguageModel"],"field_formatters":{},"frozen":false,"field_order":["groq_api_key","model","max_output_tokens","temperature","top_k","top_p","n","input_value","system_message","stream"],"beta":false},"id":"GroqModelSpecs-MTknA"},"selected":false,"width":384,"height":493,"positionAbsolute":{"x":509.27024226800756,"y":2848.279119946775},"dragging":false},{"id":"RunnableExecutor-sRB54","type":"genericNode","position":{"x":1551.8750364061798,"y":2491.3060896919587},"data":{"type":"RunnableExecutor","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Inputs","advanced":false,"dynamic":false,"info":"The inputs to pass to the runnable.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"runnable":{"type":"Runnable","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"runnable","display_name":"Runnable","advanced":false,"input_types":["Chain","AgentExecutor","Agent","Runnable"],"dynamic":false,"info":"The runnable to execute.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_core.runnables import Runnable\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Text\n\n\nclass RunnableExecComponent(CustomComponent):\n    description = \"Execute a runnable. It will try to guess the input and output keys.\"\n    display_name = \"Runnable Executor\"\n    beta: bool = True\n    field_order = [\n        \"input_key\",\n        \"output_key\",\n        \"input_value\",\n        \"runnable\",\n    ]\n\n    def build_config(self):\n        return {\n            \"input_key\": {\n                \"display_name\": \"Input Key\",\n                \"info\": \"The key to use for the input.\",\n                \"advanced\": True,\n            },\n            \"input_value\": {\n                \"display_name\": \"Inputs\",\n                \"info\": \"The inputs to pass to the runnable.\",\n            },\n            \"runnable\": {\n                \"display_name\": \"Runnable\",\n                \"info\": \"The runnable to execute.\",\n                \"input_types\": [\"Chain\", \"AgentExecutor\", \"Agent\", \"Runnable\"],\n            },\n            \"output_key\": {\n                \"display_name\": \"Output Key\",\n                \"info\": \"The key to use for the output.\",\n                \"advanced\": True,\n            },\n        }\n\n    def get_output(self, result, input_key, output_key):\n        \"\"\"\n        Retrieves the output value from the given result dictionary based on the specified input and output keys.\n\n        Args:\n            result (dict): The result dictionary containing the output value.\n            input_key (str): The key used to retrieve the input value from the result dictionary.\n            output_key (str): The key used to retrieve the output value from the result dictionary.\n\n        Returns:\n            tuple: A tuple containing the output value and the status message.\n\n        \"\"\"\n        possible_output_keys = [\"answer\", \"response\", \"output\", \"result\", \"text\"]\n        status = \"\"\n        result_value = None\n\n        if output_key in result:\n            result_value = result.get(output_key)\n        elif len(result) == 2 and input_key in result:\n            # get the other key from the result dict\n            other_key = [k for k in result if k != input_key][0]\n            if other_key == output_key:\n                result_value = result.get(output_key)\n            else:\n                status += f\"Warning: The output key is not '{output_key}'. The output key is '{other_key}'.\"\n                result_value = result.get(other_key)\n        elif len(result) == 1:\n            result_value = list(result.values())[0]\n        elif any(k in result for k in possible_output_keys):\n            for key in possible_output_keys:\n                if key in result:\n                    result_value = result.get(key)\n                    status += f\"Output key: '{key}'.\"\n                    break\n            if result_value is None:\n                result_value = result\n                status += f\"Warning: The output key is not '{output_key}'.\"\n        else:\n            result_value = result\n            status += f\"Warning: The output key is not '{output_key}'.\"\n\n        return result_value, status\n\n    def get_input_dict(self, runnable, input_key, input_value):\n        \"\"\"\n        Returns a dictionary containing the input key-value pair for the given runnable.\n\n        Args:\n            runnable: The runnable object.\n            input_key: The key for the input value.\n            input_value: The value for the input key.\n\n        Returns:\n            input_dict: A dictionary containing the input key-value pair.\n            status: A status message indicating if the input key is not in the runnable's input keys.\n        \"\"\"\n        input_dict = {}\n        status = \"\"\n        if hasattr(runnable, \"input_keys\"):\n            # Check if input_key is in the runnable's input_keys\n            if input_key in runnable.input_keys:\n                input_dict[input_key] = input_value\n            else:\n                input_dict = {k: input_value for k in runnable.input_keys}\n                status = f\"Warning: The input key is not '{input_key}'. The input key is '{runnable.input_keys}'.\"\n        return input_dict, status\n\n    def build(\n        self,\n        input_value: Text,\n        runnable: Runnable,\n        input_key: str = \"input\",\n        output_key: str = \"output\",\n    ) -> Text:\n        input_dict, status = self.get_input_dict(runnable, input_key, input_value)\n        result = runnable.invoke(input_dict)\n        result_value, _status = self.get_output(result, input_key, output_key)\n        status += _status\n        status += f\"\\n\\nOutput: {result_value}\\n\\nRaw Output: {result}\"\n        self.status = status\n        return result_value\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_key":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"input","fileTypes":[],"file_path":"","password":false,"name":"input_key","display_name":"Input Key","advanced":true,"dynamic":false,"info":"The key to use for the input.","load_from_db":false,"title_case":false,"input_types":["Text"]},"output_key":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"output","fileTypes":[],"file_path":"","password":false,"name":"output_key","display_name":"Output Key","advanced":true,"dynamic":false,"info":"The key to use for the output.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Execute a runnable. It will try to guess the input and output keys.","base_classes":["object","str","Text"],"display_name":"Runnable Executor","documentation":"","custom_fields":{"input_value":null,"runnable":null,"input_key":null,"output_key":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["input_key","output_key","input_value","runnable"],"beta":true},"id":"RunnableExecutor-sRB54"},"selected":false,"width":384,"height":373,"positionAbsolute":{"x":1551.8750364061798,"y":2491.3060896919587},"dragging":false},{"id":"TextInput-ALJ0C","type":"genericNode","position":{"x":920.6521490183363,"y":1920.9427050779832},"data":{"type":"TextInput","node":{"template":{"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Record","Text"],"dynamic":false,"info":"Text or Record to be passed as input.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Text\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["object","str","Text"],"display_name":"Text Input","documentation":"","custom_fields":{"input_value":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"TextInput-ALJ0C"},"selected":false,"width":384,"height":297,"positionAbsolute":{"x":920.6521490183363,"y":1920.9427050779832},"dragging":false},{"id":"Prompt-drVJm","type":"genericNode","position":{"x":449.9312547728805,"y":1774.0034970346712},"data":{"type":"Prompt","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import CustomComponent\nfrom langflow.field_typing import TemplateField\nfrom langflow.field_typing.prompt import Prompt\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    async def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Prompt:\n        prompt = await Prompt.from_template_and_variables(template, kwargs)\n        self.status = prompt.format_text()\n        return prompt\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"prompt","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"You are a friendly support assistant that handles appointments.\nHere is the result of the SQL Agent as context:\n{query_result}\n\nReturn to the user a user friendly response without being specific on the details given the question:\n{question}\n","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent","query_result":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"query_result","display_name":"query_result","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"question":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"question","display_name":"question","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Prompt","Record"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["query_result","question"]},"output_types":["Prompt"],"full_path":null,"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"error":null},"id":"Prompt-drVJm","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":513,"positionAbsolute":{"x":449.9312547728805,"y":1774.0034970346712},"dragging":false},{"id":"GroqModel-fq2H8","type":"genericNode","position":{"x":1387.2574597193864,"y":1752.978542430113},"data":{"type":"GroqModel","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"dynamic":false,"info":"The input to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_groq import ChatGroq\nfrom langflow.base.models.groq_constants import MODEL_NAMES\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Text\n\n\nclass GroqModel(LCModelComponent):\n    display_name: str = \"Groq\"\n    description: str = \"Generate text using Groq.\"\n    icon = \"Groq\"\n\n    field_order = [\n        \"groq_api_key\",\n        \"model\",\n        \"max_output_tokens\",\n        \"temperature\",\n        \"top_k\",\n        \"top_p\",\n        \"n\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self):\n        return {\n            \"groq_api_key\": {\n                \"display_name\": \"Groq API Key\",\n                \"info\": \"API key for the Groq API.\",\n                \"password\": True,\n            },\n            \"groq_api_base\": {\n                \"display_name\": \"Groq API Base\",\n                \"info\": \"Base URL path for API requests, leave blank if not using a proxy or service emulator.\",\n                \"advanced\": True,\n            },\n            \"max_tokens\": {\n                \"display_name\": \"Max Output Tokens\",\n                \"info\": \"The maximum number of tokens to generate.\",\n                \"advanced\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"info\": \"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\",\n            },\n            \"n\": {\n                \"display_name\": \"N\",\n                \"info\": \"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n                \"advanced\": True,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model\",\n                \"info\": \"The name of the model to use. Supported examples: gemini-pro\",\n                \"options\": MODEL_NAMES,\n            },\n            \"input_value\": {\"display_name\": \"Input\", \"info\": \"The input to the model.\"},\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        groq_api_key: str,\n        model_name: str,\n        input_value: Text,\n        groq_api_base: Optional[str] = None,\n        max_tokens: Optional[int] = None,\n        temperature: float = 0.1,\n        n: Optional[int] = 1,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        output = ChatGroq(\n            model_name=model_name,\n            max_tokens=max_tokens or None,  # type: ignore\n            temperature=temperature,\n            groq_api_base=groq_api_base,\n            n=n or 1,\n            groq_api_key=SecretStr(groq_api_key),\n            streaming=stream,\n        )\n        return self.get_chat_result(output, stream, input_value, system_message)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"groq_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"groq_api_base","display_name":"Groq API Base","advanced":true,"dynamic":false,"info":"Base URL path for API requests, leave blank if not using a proxy or service emulator.","load_from_db":false,"title_case":false,"input_types":["Text"]},"groq_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"groq_api_key","display_name":"Groq API Key","advanced":false,"dynamic":false,"info":"API key for the Groq API.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Output Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate.","load_from_db":false,"title_case":false},"model_name":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"options":["llama3-8b-8192","llama3-70b-8192","mixtral-8x7b-32768","gemma-7b-it"],"name":"model_name","display_name":"Model","advanced":false,"dynamic":false,"info":"The name of the model to use. Supported examples: gemini-pro","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"llama3-70b-8192"},"n":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":1,"fileTypes":[],"file_path":"","password":false,"name":"n","display_name":"N","advanced":true,"dynamic":false,"info":"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.","load_from_db":false,"title_case":false},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"system_message":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":0.1,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generate text using Groq.","icon":"Groq","base_classes":["object","str","Text"],"display_name":"Groq","documentation":"","custom_fields":{"groq_api_key":null,"model_name":null,"input_value":null,"groq_api_base":null,"max_tokens":null,"temperature":null,"n":null,"stream":null,"system_message":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["groq_api_key","model","max_output_tokens","temperature","top_k","top_p","n","input_value","system_message","stream"],"beta":false},"id":"GroqModel-fq2H8"},"selected":false,"width":384,"height":587,"positionAbsolute":{"x":1387.2574597193864,"y":1752.978542430113},"dragging":false}],"edges":[{"source":"GroqModelSpecs-MTknA","sourceHandle":"{œbaseClassesœ:[œBaseLanguageModelœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œGroqModelSpecsœ,œidœ:œGroqModelSpecs-MTknAœ}","target":"SQLAgent-ar5dR","targetHandle":"{œfieldNameœ:œllmœ,œidœ:œSQLAgent-ar5dRœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}","data":{"targetHandle":{"fieldName":"llm","id":"SQLAgent-ar5dR","inputTypes":null,"type":"BaseLanguageModel"},"sourceHandle":{"baseClasses":["BaseLanguageModel","Generic","object","Runnable","RunnableSerializable","Serializable"],"dataType":"GroqModelSpecs","id":"GroqModelSpecs-MTknA"}},"id":"reactflow__edge-GroqModelSpecs-MTknA{œbaseClassesœ:[œBaseLanguageModelœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œGroqModelSpecsœ,œidœ:œGroqModelSpecs-MTknAœ}-SQLAgent-ar5dR{œfieldNameœ:œllmœ,œidœ:œSQLAgent-ar5dRœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}","className":""},{"source":"SQLAgent-ar5dR","sourceHandle":"{œbaseClassesœ:[œAgentExecutorœ,œCallableœ,œChainœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œSQLAgentœ,œidœ:œSQLAgent-ar5dRœ}","target":"RunnableExecutor-sRB54","targetHandle":"{œfieldNameœ:œrunnableœ,œidœ:œRunnableExecutor-sRB54œ,œinputTypesœ:[œChainœ,œAgentExecutorœ,œAgentœ,œRunnableœ],œtypeœ:œRunnableœ}","data":{"targetHandle":{"fieldName":"runnable","id":"RunnableExecutor-sRB54","inputTypes":["Chain","AgentExecutor","Agent","Runnable"],"type":"Runnable"},"sourceHandle":{"baseClasses":["AgentExecutor","Callable","Chain","Generic","object","Runnable","RunnableSerializable","Serializable"],"dataType":"SQLAgent","id":"SQLAgent-ar5dR"}},"id":"reactflow__edge-SQLAgent-ar5dR{œbaseClassesœ:[œAgentExecutorœ,œCallableœ,œChainœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œSQLAgentœ,œidœ:œSQLAgent-ar5dRœ}-RunnableExecutor-sRB54{œfieldNameœ:œrunnableœ,œidœ:œRunnableExecutor-sRB54œ,œinputTypesœ:[œChainœ,œAgentExecutorœ,œAgentœ,œRunnableœ],œtypeœ:œRunnableœ}","className":""},{"source":"ChatInput-j3Aim","sourceHandle":"{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-j3Aimœ}","target":"RunnableExecutor-sRB54","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œRunnableExecutor-sRB54œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"RunnableExecutor-sRB54","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["Message","object","str","Text"],"dataType":"ChatInput","id":"ChatInput-j3Aim"}},"id":"reactflow__edge-ChatInput-j3Aim{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-j3Aimœ}-RunnableExecutor-sRB54{œfieldNameœ:œinput_valueœ,œidœ:œRunnableExecutor-sRB54œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","className":""},{"source":"RunnableExecutor-sRB54","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œRunnableExecutorœ,œidœ:œRunnableExecutor-sRB54œ}","target":"Prompt-drVJm","targetHandle":"{œfieldNameœ:œquery_resultœ,œidœ:œPrompt-drVJmœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"query_result","id":"Prompt-drVJm","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"RunnableExecutor","id":"RunnableExecutor-sRB54"}},"id":"reactflow__edge-RunnableExecutor-sRB54{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œRunnableExecutorœ,œidœ:œRunnableExecutor-sRB54œ}-Prompt-drVJm{œfieldNameœ:œquery_resultœ,œidœ:œPrompt-drVJmœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"ChatInput-j3Aim","sourceHandle":"{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-j3Aimœ}","target":"Prompt-drVJm","targetHandle":"{œfieldNameœ:œquestionœ,œidœ:œPrompt-drVJmœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"question","id":"Prompt-drVJm","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Message","object","str","Text"],"dataType":"ChatInput","id":"ChatInput-j3Aim"}},"id":"reactflow__edge-ChatInput-j3Aim{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-j3Aimœ}-Prompt-drVJm{œfieldNameœ:œquestionœ,œidœ:œPrompt-drVJmœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"Prompt-drVJm","sourceHandle":"{œbaseClassesœ:[œPromptœ,œRecordœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-drVJmœ}","target":"TextInput-ALJ0C","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œTextInput-ALJ0Cœ,œinputTypesœ:[œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"TextInput-ALJ0C","inputTypes":["Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Prompt","Record"],"dataType":"Prompt","id":"Prompt-drVJm"}},"id":"reactflow__edge-Prompt-drVJm{œbaseClassesœ:[œPromptœ,œRecordœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-drVJmœ}-TextInput-ALJ0C{œfieldNameœ:œinput_valueœ,œidœ:œTextInput-ALJ0Cœ,œinputTypesœ:[œRecordœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"TextInput-ALJ0C","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-ALJ0Cœ}","target":"GroqModel-fq2H8","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œGroqModel-fq2H8œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"GroqModel-fq2H8","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"TextInput","id":"TextInput-ALJ0C"}},"id":"reactflow__edge-TextInput-ALJ0C{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-ALJ0Cœ}-GroqModel-fq2H8{œfieldNameœ:œinput_valueœ,œidœ:œGroqModel-fq2H8œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","className":""},{"source":"GroqModel-fq2H8","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œGroqModelœ,œidœ:œGroqModel-fq2H8œ}","target":"ChatOutput-pThdQ","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-pThdQœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-pThdQ","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"GroqModel","id":"GroqModel-fq2H8"}},"id":"reactflow__edge-GroqModel-fq2H8{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œGroqModelœ,œidœ:œGroqModel-fq2H8œ}-ChatOutput-pThdQ{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-pThdQœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","className":""}],"viewport":{"x":201.98275370209205,"y":-718.3124964104732,"zoom":0.4822990922920671}},"description":"Db schema for handling appointments update","name":"DB insertion v1","last_tested_version":"1.0.0a61","is_component":false}