{"id":"b2344f3e-0c5b-4583-8c9c-49a3a872f8d4","data":{"nodes":[{"id":"SQLGenerator-MZ20F","type":"genericNode","position":{"x":948.2358469968742,"y":1012.4253538745502},"data":{"type":"SQLGenerator","node":{"template":{"db":{"type":"SQLDatabase","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"db","display_name":"Database","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input Value","advanced":false,"dynamic":false,"info":"The input value to pass to the chain.","load_from_db":false,"title_case":false,"input_types":["Text"]},"llm":{"type":"BaseLanguageModel","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"llm","display_name":"LLM","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"prompt":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"prompt","display_name":"Prompt","advanced":false,"dynamic":false,"info":"The prompt must contain `{question}`.","load_from_db":false,"title_case":false,"input_types":["Text"]},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain.chains import create_sql_query_chain\nfrom langchain_community.utilities.sql_database import SQLDatabase\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import Runnable\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import BaseLanguageModel, Text\n\n\nclass SQLGeneratorComponent(CustomComponent):\n    display_name = \"Natural Language to SQL\"\n    description = \"Generate SQL from natural language.\"\n\n    def build_config(self):\n        return {\n            \"db\": {\"display_name\": \"Database\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"prompt\": {\n                \"display_name\": \"Prompt\",\n                \"info\": \"The prompt must contain `{question}`.\",\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"info\": \"The number of results per select statement to return. If 0, no limit.\",\n            },\n            \"input_value\": {\n                \"display_name\": \"Input Value\",\n                \"info\": \"The input value to pass to the chain.\",\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        db: SQLDatabase,\n        llm: BaseLanguageModel,\n        top_k: int = 5,\n        prompt: Optional[Text] = None,\n    ) -> Text:\n        if prompt:\n            prompt_template = PromptTemplate.from_template(template=prompt)\n        else:\n            prompt_template = None\n\n        if top_k < 1:\n            raise ValueError(\"Top K must be greater than 0.\")\n\n        if not prompt_template:\n            sql_query_chain = create_sql_query_chain(llm=llm, db=db, k=top_k)\n        else:\n            # Check if {question} is in the prompt\n            if \"{question}\" not in prompt_template.template or \"question\" not in prompt_template.input_variables:\n                raise ValueError(\"Prompt must contain `{question}` to be used with Natural Language to SQL.\")\n            sql_query_chain = create_sql_query_chain(llm=llm, db=db, prompt=prompt_template, k=top_k)\n        query_writer: Runnable = sql_query_chain | {\"query\": lambda x: x.replace(\"SQLQuery:\", \"\").strip()}\n        response = query_writer.invoke({\"question\": f\"Remember to not process question that ask about inserting, modifying, updating or deleting. Just reading is available. Here is the question:{input_value.text}\"})\n        query = response.get(\"query\")\n        self.status = query\n        return query\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"top_k":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":5,"fileTypes":[],"file_path":"","password":false,"name":"top_k","display_name":"Top K","advanced":false,"dynamic":false,"info":"The number of results per select statement to return. If 0, no limit.","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generate SQL from natural language.","base_classes":["object","str","Text"],"display_name":"Natural Language to SQL","documentation":"","custom_fields":{"input_value":null,"db":null,"llm":null,"top_k":null,"prompt":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":true},"id":"SQLGenerator-MZ20F","description":"Generate SQL from natural language.","display_name":"Natural Language to SQL"},"selected":true,"width":384,"height":573,"positionAbsolute":{"x":948.2358469968742,"y":1012.4253538745502},"dragging":false},{"id":"SQLExecutor-AXJKi","type":"genericNode","position":{"x":1517.943476181827,"y":705.5779413393566},"data":{"type":"SQLExecutor","node":{"template":{"add_error":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":true,"fileTypes":[],"file_path":"","password":false,"name":"add_error","display_name":"Add Error","advanced":false,"dynamic":false,"info":"Add the error to the result.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\nfrom langchain_community.utilities import SQLDatabase\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Text\n\n\nclass SQLExecutorComponent(CustomComponent):\n    display_name = \"SQL Executor\"\n    description = \"Execute SQL query.\"\n    beta: bool = True\n\n    def build_config(self):\n        return {\n            \"database_url\": {\n                \"display_name\": \"Database URL\",\n                \"info\": \"The URL of the database.\",\n            },\n            \"include_columns\": {\n                \"display_name\": \"Include Columns\",\n                \"info\": \"Include columns in the result.\",\n            },\n            \"passthrough\": {\n                \"display_name\": \"Passthrough\",\n                \"info\": \"If an error occurs, return the query instead of raising an exception.\",\n            },\n            \"add_error\": {\n                \"display_name\": \"Add Error\",\n                \"info\": \"Add the error to the result.\",\n            },\n        }\n\n    def clean_up_uri(self, uri: str) -> str:\n        if uri.startswith(\"postgresql://\"):\n            uri = uri.replace(\"postgresql://\", \"postgres://\")\n        return uri.strip()\n\n    def build(\n        self,\n        query: str,\n        database_url: str,\n        include_columns: bool = False,\n        passthrough: bool = False,\n        add_error: bool = False,\n    ) -> Text:\n        error = None\n        try:\n            database = SQLDatabase.from_uri(database_url)\n        except Exception as e:\n            raise ValueError(f\"An error occurred while connecting to the database: {e}\")\n        try:\n            tool = QuerySQLDataBaseTool(db=database)\n            result = tool.run(query, include_columns=include_columns)\n            self.status = result\n        except Exception as e:\n            result = Text(e)\n            self.status = result\n            if not passthrough:\n                raise e\n            error = repr(e)\n\n        if add_error and error is not None:\n            result = f\"{result}\\n\\nError: {error}\\n\\nQuery: {query}\"\n        elif error is not None:\n            # Then we won't add the error to the result\n            # but since we are in passthrough mode, we will return the query\n            result = query\n\n        return result\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"database_url":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"database_url","display_name":"Database URL","advanced":false,"dynamic":false,"info":"The URL of the database.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"postgresql+psycopg2://myuser:mypassword@vector_db:5432/mydatabase2"},"include_columns":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"include_columns","display_name":"Include Columns","advanced":false,"dynamic":false,"info":"Include columns in the result.","load_from_db":false,"title_case":false},"passthrough":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"passthrough","display_name":"Passthrough","advanced":false,"dynamic":false,"info":"If an error occurs, return the query instead of raising an exception.","load_from_db":false,"title_case":false},"query":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"query","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Execute SQL query.","base_classes":["object","str","Text"],"display_name":"SQL Executor","documentation":"","custom_fields":{"query":null,"database_url":null,"include_columns":null,"passthrough":null,"add_error":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":true},"id":"SQLExecutor-AXJKi"},"selected":false,"width":384,"height":621,"positionAbsolute":{"x":1517.943476181827,"y":705.5779413393566},"dragging":false},{"id":"SQLDatabase-2m7jx","type":"genericNode","position":{"x":996.7766436322605,"y":561.0443419757911},"data":{"type":"SQLDatabase","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_experimental.sql.base import SQLDatabase\n\nfrom langflow.custom import CustomComponent\n\n\nclass SQLDatabaseComponent(CustomComponent):\n    display_name = \"SQLDatabase\"\n    description = \"SQL Database\"\n\n    def build_config(self):\n        return {\n            \"uri\": {\"display_name\": \"URI\", \"info\": \"URI to the database.\"},\n        }\n\n    def clean_up_uri(self, uri: str) -> str:\n        if uri.startswith(\"postgresql://\"):\n            uri = uri.replace(\"postgresql://\", \"postgres://\")\n        return uri.strip()\n\n    def build(self, uri: str) -> SQLDatabase:\n        uri = self.clean_up_uri(uri)\n        return SQLDatabase.from_uri(uri)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"uri":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"uri","display_name":"URI","advanced":false,"dynamic":false,"info":"URI to the database.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"postgresql+psycopg2://myuser:mypassword@vector_db:5432/mydatabase2"},"_type":"CustomComponent"},"description":"SQL Database","base_classes":["object","SQLDatabase"],"display_name":"SQLDatabase","documentation":"","custom_fields":{"uri":null},"output_types":["SQLDatabase"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"SQLDatabase-2m7jx"},"selected":false,"width":384,"height":297,"positionAbsolute":{"x":996.7766436322605,"y":561.0443419757911},"dragging":false},{"id":"TextOutput-DIumz","type":"genericNode","position":{"x":1446.294664498886,"y":1550.8818142767504},"data":{"type":"TextOutput","node":{"template":{"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Record","Text"],"dynamic":false,"info":"Text or Record to be passed as output.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextOutput(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Text\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as output.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(self, input_value: Optional[Text] = \"\", record_template: Optional[str] = \"\") -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Display a text output in the Playground.","icon":"type","base_classes":["object","str","Text"],"display_name":"Text Output","documentation":"","custom_fields":{"input_value":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"TextOutput-DIumz"},"selected":false,"width":384,"height":297,"positionAbsolute":{"x":1446.294664498886,"y":1550.8818142767504},"dragging":false},{"id":"GroqModelSpecs-rjFzP","type":"genericNode","position":{"x":353.50637078203374,"y":616.7210416859905},"data":{"type":"GroqModelSpecs","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_groq import ChatGroq\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.groq_constants import MODEL_NAMES\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import BaseLanguageModel\n\n\nclass GroqModelSpecs(LCModelComponent):\n    display_name: str = \"Groq\"\n    description: str = \"Generate text using Groq.\"\n    icon = \"Groq\"\n\n    field_order = [\n        \"groq_api_key\",\n        \"model\",\n        \"max_output_tokens\",\n        \"temperature\",\n        \"top_k\",\n        \"top_p\",\n        \"n\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self):\n        return {\n            \"groq_api_key\": {\n                \"display_name\": \"Groq API Key\",\n                \"info\": \"API key for the Groq API.\",\n                \"password\": True,\n            },\n            \"groq_api_base\": {\n                \"display_name\": \"Groq API Base\",\n                \"info\": \"Base URL path for API requests, leave blank if not using a proxy or service emulator.\",\n                \"advanced\": True,\n            },\n            \"max_tokens\": {\n                \"display_name\": \"Max Output Tokens\",\n                \"info\": \"The maximum number of tokens to generate.\",\n                \"advanced\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"info\": \"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\",\n            },\n            \"n\": {\n                \"display_name\": \"N\",\n                \"info\": \"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n                \"advanced\": True,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model\",\n                \"info\": \"The name of the model to use. Supported examples: gemini-pro\",\n                \"options\": MODEL_NAMES,\n            },\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        groq_api_key: str,\n        model_name: str,\n        groq_api_base: Optional[str] = None,\n        max_tokens: Optional[int] = None,\n        temperature: float = 0.1,\n        n: Optional[int] = 1,\n        stream: bool = False,\n    ) -> BaseLanguageModel:\n        return ChatGroq(\n            model_name=model_name,\n            max_tokens=max_tokens or None,  # type: ignore\n            temperature=temperature,\n            groq_api_base=groq_api_base,\n            n=n or 1,\n            groq_api_key=SecretStr(groq_api_key),\n            streaming=stream,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"groq_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"groq_api_base","display_name":"Groq API Base","advanced":true,"dynamic":false,"info":"Base URL path for API requests, leave blank if not using a proxy or service emulator.","load_from_db":false,"title_case":false,"input_types":["Text"]},"groq_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"groq_api_key","display_name":"Groq API Key","advanced":false,"dynamic":false,"info":"API key for the Groq API.","load_from_db":true,"title_case":false,"input_types":["Text"],"value":""},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Output Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate.","load_from_db":false,"title_case":false},"model_name":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"options":["llama3-8b-8192","llama3-70b-8192","mixtral-8x7b-32768","gemma-7b-it"],"name":"model_name","display_name":"Model","advanced":false,"dynamic":false,"info":"The name of the model to use. Supported examples: gemini-pro","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"llama3-70b-8192"},"n":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":1,"fileTypes":[],"file_path":"","password":false,"name":"n","display_name":"N","advanced":true,"dynamic":false,"info":"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.","load_from_db":false,"title_case":false},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":0.1,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generate text using Groq.","icon":"Groq","base_classes":["BaseLanguageModel","Generic","object","Runnable","RunnableSerializable","Serializable"],"display_name":"Groq","documentation":"","custom_fields":{"groq_api_key":null,"model_name":null,"groq_api_base":null,"max_tokens":null,"temperature":null,"n":null,"stream":null},"output_types":["BaseLanguageModel"],"field_formatters":{},"frozen":false,"field_order":["groq_api_key","model","max_output_tokens","temperature","top_k","top_p","n","input_value","system_message","stream"],"beta":false},"id":"GroqModelSpecs-rjFzP"},"selected":false,"width":384,"height":493,"positionAbsolute":{"x":353.50637078203374,"y":616.7210416859905},"dragging":false},{"id":"Prompt-B1qsE","type":"genericNode","position":{"x":1966.9925520351112,"y":1446.711014948042},"data":{"type":"Prompt","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import CustomComponent\nfrom langflow.field_typing import TemplateField\nfrom langflow.field_typing.prompt import Prompt\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    async def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Prompt:\n        prompt = await Prompt.from_template_and_variables(template, kwargs)\n        self.status = prompt.format_text()\n        return prompt\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"prompt","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"Here is the result of the query as a context:\n{query_result}\n\nAnswer this question using the context from the query:\n{question}\n","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent","query_result":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"query_result","display_name":"query_result","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"question":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"question","display_name":"question","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Prompt","Record"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["query_result","question"]},"output_types":["Prompt"],"full_path":null,"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"error":null},"id":"Prompt-B1qsE","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":513,"positionAbsolute":{"x":1966.9925520351112,"y":1446.711014948042},"dragging":false},{"id":"GroqModel-pNb5P","type":"genericNode","position":{"x":2957.631922840257,"y":1427.3714308909437},"data":{"type":"GroqModel","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"dynamic":false,"info":"The input to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_groq import ChatGroq\nfrom langflow.base.models.groq_constants import MODEL_NAMES\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Text\n\n\nclass GroqModel(LCModelComponent):\n    display_name: str = \"Groq\"\n    description: str = \"Generate text using Groq.\"\n    icon = \"Groq\"\n\n    field_order = [\n        \"groq_api_key\",\n        \"model\",\n        \"max_output_tokens\",\n        \"temperature\",\n        \"top_k\",\n        \"top_p\",\n        \"n\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self):\n        return {\n            \"groq_api_key\": {\n                \"display_name\": \"Groq API Key\",\n                \"info\": \"API key for the Groq API.\",\n                \"password\": True,\n            },\n            \"groq_api_base\": {\n                \"display_name\": \"Groq API Base\",\n                \"info\": \"Base URL path for API requests, leave blank if not using a proxy or service emulator.\",\n                \"advanced\": True,\n            },\n            \"max_tokens\": {\n                \"display_name\": \"Max Output Tokens\",\n                \"info\": \"The maximum number of tokens to generate.\",\n                \"advanced\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"info\": \"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\",\n            },\n            \"n\": {\n                \"display_name\": \"N\",\n                \"info\": \"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n                \"advanced\": True,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model\",\n                \"info\": \"The name of the model to use. Supported examples: gemini-pro\",\n                \"options\": MODEL_NAMES,\n            },\n            \"input_value\": {\"display_name\": \"Input\", \"info\": \"The input to the model.\"},\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        groq_api_key: str,\n        model_name: str,\n        input_value: Text,\n        groq_api_base: Optional[str] = None,\n        max_tokens: Optional[int] = None,\n        temperature: float = 0.1,\n        n: Optional[int] = 1,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        output = ChatGroq(\n            model_name=model_name,\n            max_tokens=max_tokens or None,  # type: ignore\n            temperature=temperature,\n            groq_api_base=groq_api_base,\n            n=n or 1,\n            groq_api_key=SecretStr(groq_api_key),\n            streaming=stream,\n        )\n        return self.get_chat_result(output, stream, input_value, system_message)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"groq_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"groq_api_base","display_name":"Groq API Base","advanced":true,"dynamic":false,"info":"Base URL path for API requests, leave blank if not using a proxy or service emulator.","load_from_db":false,"title_case":false,"input_types":["Text"]},"groq_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"groq_api_key","display_name":"Groq API Key","advanced":false,"dynamic":false,"info":"API key for the Groq API.","load_from_db":true,"title_case":false,"input_types":["Text"],"value":""},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Output Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate.","load_from_db":false,"title_case":false},"model_name":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"options":["llama3-8b-8192","llama3-70b-8192","mixtral-8x7b-32768","gemma-7b-it"],"name":"model_name","display_name":"Model","advanced":false,"dynamic":false,"info":"The name of the model to use. Supported examples: gemini-pro","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"llama3-70b-8192"},"n":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":1,"fileTypes":[],"file_path":"","password":false,"name":"n","display_name":"N","advanced":true,"dynamic":false,"info":"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.","load_from_db":false,"title_case":false},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"system_message":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":0.1,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generate text using Groq.","icon":"Groq","base_classes":["object","str","Text"],"display_name":"Groq","documentation":"","custom_fields":{"groq_api_key":null,"model_name":null,"input_value":null,"groq_api_base":null,"max_tokens":null,"temperature":null,"n":null,"stream":null,"system_message":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["groq_api_key","model","max_output_tokens","temperature","top_k","top_p","n","input_value","system_message","stream"],"beta":false},"id":"GroqModel-pNb5P"},"selected":false,"width":384,"height":587,"dragging":false,"positionAbsolute":{"x":2957.631922840257,"y":1427.3714308909437}},{"id":"TextInput-UzEVJ","type":"genericNode","position":{"x":2474.340775356666,"y":1591.8421437407314},"data":{"type":"TextInput","node":{"template":{"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Record","Text"],"dynamic":false,"info":"Text or Record to be passed as input.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Text\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["object","str","Text"],"display_name":"Text Input","documentation":"","custom_fields":{"input_value":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"TextInput-UzEVJ"},"selected":false,"width":384,"height":297,"positionAbsolute":{"x":2474.340775356666,"y":1591.8421437407314},"dragging":false},{"id":"ChatOutput-CPNnv","type":"genericNode","position":{"x":3430.944053397555,"y":1577.6567528603462},"data":{"type":"ChatOutput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        return_message: Optional[bool] = False,\n    ) -> Union[Message, Text]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            files=files,\n            return_message=return_message,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"return_message":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_message","display_name":"Return Message","advanced":true,"dynamic":false,"info":"Return the message as a Message containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"AI","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message","object","str","Text"],"display_name":"Chat Output","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"files":null,"return_message":null},"output_types":["Message","Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatOutput-CPNnv"},"selected":false,"width":384,"height":297,"positionAbsolute":{"x":3430.944053397555,"y":1577.6567528603462},"dragging":false},{"id":"ChatInput-ILNh2","type":"genericNode","position":{"x":312.3080268067115,"y":1572.2117533879089},"data":{"type":"ChatInput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.schema.message import Message\nfrom langflow.field_typing import Text\nfrom typing import Union\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    def build_config(self):\n        build_config = super().build_config()\n        build_config[\"input_value\"] = {\n            \"input_types\": [],\n            \"display_name\": \"Text\",\n            \"multiline\": True,\n        }\n        build_config[\"return_message\"] = {\n            \"display_name\": \"Return Record\",\n            \"advanced\": True,\n        }\n\n        return build_config\n\n    def build(\n        self,\n        sender: Optional[str] = \"User\",\n        sender_name: Optional[str] = \"User\",\n        input_value: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        session_id: Optional[str] = None,\n        return_message: Optional[bool] = True,\n    ) -> Union[Message, Text]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            files=files,\n            session_id=session_id,\n            return_message=return_message,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":[],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"value":"Can you add a collection named \"yoiamaimposter\""},"return_message":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":true,"fileTypes":[],"file_path":"","password":false,"name":"return_message","display_name":"Return Record","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["Message","object","str","Text"],"display_name":"Chat Input","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"files":null,"session_id":null,"return_message":null},"output_types":["Message","Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatInput-ILNh2"},"selected":false,"width":384,"height":297,"positionAbsolute":{"x":312.3080268067115,"y":1572.2117533879089},"dragging":false}],"edges":[{"source":"SQLGenerator-MZ20F","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œSQLGeneratorœ,œidœ:œSQLGenerator-MZ20Fœ}","target":"SQLExecutor-AXJKi","targetHandle":"{œfieldNameœ:œqueryœ,œidœ:œSQLExecutor-AXJKiœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"query","id":"SQLExecutor-AXJKi","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"SQLGenerator","id":"SQLGenerator-MZ20F"}},"id":"reactflow__edge-SQLGenerator-MZ20F{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œSQLGeneratorœ,œidœ:œSQLGenerator-MZ20Fœ}-SQLExecutor-AXJKi{œfieldNameœ:œqueryœ,œidœ:œSQLExecutor-AXJKiœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","className":""},{"source":"SQLExecutor-AXJKi","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œSQLExecutorœ,œidœ:œSQLExecutor-AXJKiœ}","target":"TextOutput-DIumz","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-DIumzœ,œinputTypesœ:[œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"TextOutput-DIumz","inputTypes":["Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"SQLExecutor","id":"SQLExecutor-AXJKi"}},"id":"reactflow__edge-SQLExecutor-AXJKi{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œSQLExecutorœ,œidœ:œSQLExecutor-AXJKiœ}-TextOutput-DIumz{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-DIumzœ,œinputTypesœ:[œRecordœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"GroqModelSpecs-rjFzP","sourceHandle":"{œbaseClassesœ:[œBaseLanguageModelœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œGroqModelSpecsœ,œidœ:œGroqModelSpecs-rjFzPœ}","target":"SQLGenerator-MZ20F","targetHandle":"{œfieldNameœ:œllmœ,œidœ:œSQLGenerator-MZ20Fœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}","data":{"targetHandle":{"fieldName":"llm","id":"SQLGenerator-MZ20F","inputTypes":null,"type":"BaseLanguageModel"},"sourceHandle":{"baseClasses":["BaseLanguageModel","Generic","object","Runnable","RunnableSerializable","Serializable"],"dataType":"GroqModelSpecs","id":"GroqModelSpecs-rjFzP"}},"id":"reactflow__edge-GroqModelSpecs-rjFzP{œbaseClassesœ:[œBaseLanguageModelœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œGroqModelSpecsœ,œidœ:œGroqModelSpecs-rjFzPœ}-SQLGenerator-MZ20F{œfieldNameœ:œllmœ,œidœ:œSQLGenerator-MZ20Fœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}","className":""},{"source":"SQLDatabase-2m7jx","sourceHandle":"{œbaseClassesœ:[œobjectœ,œSQLDatabaseœ],œdataTypeœ:œSQLDatabaseœ,œidœ:œSQLDatabase-2m7jxœ}","target":"SQLGenerator-MZ20F","targetHandle":"{œfieldNameœ:œdbœ,œidœ:œSQLGenerator-MZ20Fœ,œinputTypesœ:null,œtypeœ:œSQLDatabaseœ}","data":{"targetHandle":{"fieldName":"db","id":"SQLGenerator-MZ20F","inputTypes":null,"type":"SQLDatabase"},"sourceHandle":{"baseClasses":["object","SQLDatabase"],"dataType":"SQLDatabase","id":"SQLDatabase-2m7jx"}},"id":"reactflow__edge-SQLDatabase-2m7jx{œbaseClassesœ:[œobjectœ,œSQLDatabaseœ],œdataTypeœ:œSQLDatabaseœ,œidœ:œSQLDatabase-2m7jxœ}-SQLGenerator-MZ20F{œfieldNameœ:œdbœ,œidœ:œSQLGenerator-MZ20Fœ,œinputTypesœ:null,œtypeœ:œSQLDatabaseœ}"},{"source":"TextOutput-DIumz","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextOutputœ,œidœ:œTextOutput-DIumzœ}","target":"Prompt-B1qsE","targetHandle":"{œfieldNameœ:œquery_resultœ,œidœ:œPrompt-B1qsEœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"query_result","id":"Prompt-B1qsE","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"TextOutput","id":"TextOutput-DIumz"}},"id":"reactflow__edge-TextOutput-DIumz{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextOutputœ,œidœ:œTextOutput-DIumzœ}-Prompt-B1qsE{œfieldNameœ:œquery_resultœ,œidœ:œPrompt-B1qsEœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"},{"source":"Prompt-B1qsE","sourceHandle":"{œbaseClassesœ:[œPromptœ,œRecordœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-B1qsEœ}","target":"TextInput-UzEVJ","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œTextInput-UzEVJœ,œinputTypesœ:[œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"TextInput-UzEVJ","inputTypes":["Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Prompt","Record"],"dataType":"Prompt","id":"Prompt-B1qsE"}},"id":"reactflow__edge-Prompt-B1qsE{œbaseClassesœ:[œPromptœ,œRecordœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-B1qsEœ}-TextInput-UzEVJ{œfieldNameœ:œinput_valueœ,œidœ:œTextInput-UzEVJœ,œinputTypesœ:[œRecordœ,œTextœ],œtypeœ:œstrœ}"},{"source":"TextInput-UzEVJ","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-UzEVJœ}","target":"GroqModel-pNb5P","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œGroqModel-pNb5Pœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"GroqModel-pNb5P","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"TextInput","id":"TextInput-UzEVJ"}},"id":"reactflow__edge-TextInput-UzEVJ{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-UzEVJœ}-GroqModel-pNb5P{œfieldNameœ:œinput_valueœ,œidœ:œGroqModel-pNb5Pœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"},{"source":"GroqModel-pNb5P","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œGroqModelœ,œidœ:œGroqModel-pNb5Pœ}","target":"ChatOutput-CPNnv","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-CPNnvœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-CPNnv","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"GroqModel","id":"GroqModel-pNb5P"}},"id":"reactflow__edge-GroqModel-pNb5P{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œGroqModelœ,œidœ:œGroqModel-pNb5Pœ}-ChatOutput-CPNnv{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-CPNnvœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"},{"source":"ChatInput-ILNh2","sourceHandle":"{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-ILNh2œ}","target":"Prompt-B1qsE","targetHandle":"{œfieldNameœ:œquestionœ,œidœ:œPrompt-B1qsEœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"question","id":"Prompt-B1qsE","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Message","object","str","Text"],"dataType":"ChatInput","id":"ChatInput-ILNh2"}},"id":"reactflow__edge-ChatInput-ILNh2{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-ILNh2œ}-Prompt-B1qsE{œfieldNameœ:œquestionœ,œidœ:œPrompt-B1qsEœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"},{"source":"ChatInput-ILNh2","sourceHandle":"{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-ILNh2œ}","target":"SQLGenerator-MZ20F","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œSQLGenerator-MZ20Fœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"SQLGenerator-MZ20F","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["Message","object","str","Text"],"dataType":"ChatInput","id":"ChatInput-ILNh2"}},"id":"reactflow__edge-ChatInput-ILNh2{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-ILNh2œ}-SQLGenerator-MZ20F{œfieldNameœ:œinput_valueœ,œidœ:œSQLGenerator-MZ20Fœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"}],"viewport":{"x":173.92946184793288,"y":-53.934745050270294,"zoom":0.37157920511692377}},"description":"This flow execute sql queries from natural language questions","name":"Ask your DB","last_tested_version":"1.0.0a61","is_component":false}